{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#conda install azure-common azure-ai-ml==0.1.0b6 mltable==0.1.0b3 azureml_dataprep azureml_dataprep_rslex responsibleai~=0.18.0 raiwidgets~=0.18.0 pandas pyarrow shap"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "\n",
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azureml.mlflow import register_model\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "#connect to the workspace\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client =  MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: ./config.json\n"
        }
      ],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"trainingcompute\""
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\r\n",
        "\r\n",
        "all_compute_names = [x.name for x in ml_client.compute.list()]\r\n",
        "\r\n",
        "if compute_name in all_compute_names:\r\n",
        "    print(f\"Found existing compute: {compute_name}\")\r\n",
        "else:\r\n",
        "    my_compute = AmlCompute(\r\n",
        "        name=compute_name,\r\n",
        "        size=\"Standard_DS2_v2\",\r\n",
        "        min_instances=0,\r\n",
        "        max_instances=4,\r\n",
        "        idle_time_before_scale_down=3600\r\n",
        "    )\r\n",
        "    ml_client.compute.begin_create_or_update(my_compute)\r\n",
        "    print(\"Initiated compute creation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute: trainingcompute\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_emp_attrition_classifier_version_string = '1'\r\n",
        "version='1'"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv('data/WA_Fn-UseC_-HR-Employee-Attrition.csv')"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(data_df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      Age Attrition     BusinessTravel  DailyRate              Department  \\\n0      41       Yes      Travel_Rarely       1102                   Sales   \n1      49        No  Travel_Frequently        279  Research & Development   \n2      37       Yes      Travel_Rarely       1373  Research & Development   \n3      33        No  Travel_Frequently       1392  Research & Development   \n4      27        No      Travel_Rarely        591  Research & Development   \n...   ...       ...                ...        ...                     ...   \n1465   36        No  Travel_Frequently        884  Research & Development   \n1466   39        No      Travel_Rarely        613  Research & Development   \n1467   27        No      Travel_Rarely        155  Research & Development   \n1468   49        No  Travel_Frequently       1023                   Sales   \n1469   34        No      Travel_Rarely        628  Research & Development   \n\n      DistanceFromHome  Education EducationField  EmployeeCount  \\\n0                    1          2  Life Sciences              1   \n1                    8          1  Life Sciences              1   \n2                    2          2          Other              1   \n3                    3          4  Life Sciences              1   \n4                    2          1        Medical              1   \n...                ...        ...            ...            ...   \n1465                23          2        Medical              1   \n1466                 6          1        Medical              1   \n1467                 4          3  Life Sciences              1   \n1468                 2          3        Medical              1   \n1469                 8          3        Medical              1   \n\n      EmployeeNumber  ...  RelationshipSatisfaction StandardHours  \\\n0                  1  ...                         1            80   \n1                  2  ...                         4            80   \n2                  4  ...                         2            80   \n3                  5  ...                         3            80   \n4                  7  ...                         4            80   \n...              ...  ...                       ...           ...   \n1465            2061  ...                         3            80   \n1466            2062  ...                         1            80   \n1467            2064  ...                         2            80   \n1468            2065  ...                         4            80   \n1469            2068  ...                         1            80   \n\n      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n0                    0                  8                      0   \n1                    1                 10                      3   \n2                    0                  7                      3   \n3                    0                  8                      3   \n4                    1                  6                      3   \n...                ...                ...                    ...   \n1465                 1                 17                      3   \n1466                 1                  9                      5   \n1467                 1                  6                      0   \n1468                 0                 17                      3   \n1469                 0                  6                      3   \n\n     WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n0                  1               6                  4   \n1                  3              10                  7   \n2                  3               0                  0   \n3                  3               8                  7   \n4                  3               2                  2   \n...              ...             ...                ...   \n1465               3               5                  2   \n1466               3               7                  7   \n1467               3               6                  2   \n1468               2               9                  6   \n1469               4               4                  3   \n\n      YearsSinceLastPromotion  YearsWithCurrManager  \n0                           0                     5  \n1                           1                     7  \n2                           0                     0  \n3                           3                     0  \n4                           2                     2  \n...                       ...                   ...  \n1465                        0                     3  \n1466                        1                     7  \n1467                        0                     3  \n1468                        0                     8  \n1469                        1                     2  \n\n[1470 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Attrition</th>\n      <th>BusinessTravel</th>\n      <th>DailyRate</th>\n      <th>Department</th>\n      <th>DistanceFromHome</th>\n      <th>Education</th>\n      <th>EducationField</th>\n      <th>EmployeeCount</th>\n      <th>EmployeeNumber</th>\n      <th>...</th>\n      <th>RelationshipSatisfaction</th>\n      <th>StandardHours</th>\n      <th>StockOptionLevel</th>\n      <th>TotalWorkingYears</th>\n      <th>TrainingTimesLastYear</th>\n      <th>WorkLifeBalance</th>\n      <th>YearsAtCompany</th>\n      <th>YearsInCurrentRole</th>\n      <th>YearsSinceLastPromotion</th>\n      <th>YearsWithCurrManager</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1102</td>\n      <td>Sales</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>279</td>\n      <td>Research &amp; Development</td>\n      <td>8</td>\n      <td>1</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1373</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>80</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>1392</td>\n      <td>Research &amp; Development</td>\n      <td>3</td>\n      <td>4</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>7</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>591</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>7</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1465</th>\n      <td>36</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>884</td>\n      <td>Research &amp; Development</td>\n      <td>23</td>\n      <td>2</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2061</td>\n      <td>...</td>\n      <td>3</td>\n      <td>80</td>\n      <td>1</td>\n      <td>17</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1466</th>\n      <td>39</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>613</td>\n      <td>Research &amp; Development</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2062</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1467</th>\n      <td>27</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>155</td>\n      <td>Research &amp; Development</td>\n      <td>4</td>\n      <td>3</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>2064</td>\n      <td>...</td>\n      <td>2</td>\n      <td>80</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1468</th>\n      <td>49</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>1023</td>\n      <td>Sales</td>\n      <td>2</td>\n      <td>3</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2065</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>0</td>\n      <td>17</td>\n      <td>3</td>\n      <td>2</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1469</th>\n      <td>34</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>628</td>\n      <td>Research &amp; Development</td>\n      <td>8</td>\n      <td>3</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2068</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>1470 rows × 35 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Employee count as all values are 1 and hence attrition is independent of this feature\r\n",
        "data_df = data_df.drop(['EmployeeCount'], axis=1)\r\n",
        "# Dropping Employee Number since it is merely an identifier\r\n",
        "data_df = data_df.drop(['EmployeeNumber'], axis=1)\r\n",
        "data_df = data_df.drop(['Over18'], axis=1)\r\n",
        "\r\n",
        "# Since all values are 80\r\n",
        "data_df = data_df.drop(['StandardHours'], axis=1)\r\n",
        "\r\n",
        "# Changing target values to a more meaningful words\r\n",
        "target_map = {'Yes': 'Leaving', 'No': 'Staying'}\r\n",
        "data_df[\"Attrition\"] = data_df[\"Attrition\"].apply(lambda x: target_map[x])\r\n",
        "\r\n",
        "target_column = \"Attrition\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data_df, test_size=0.3)\r\n",
        "\r\n",
        "train_data = train.to_parquet('data/train_dataset.parquet')\r\n",
        "test_data = test.to_parquet('data/test_dataset.parquet')"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_data_path = 'data/all_emp_dataset.parquet'\r\n",
        "\r\n",
        "train_data = train.to_parquet('data/train_dataset.parquet')\r\n",
        "test_data = test.to_parquet('data/test_dataset.parquet')\r\n",
        "all_emp_data_parquet = data_df.to_parquet(source_data_path)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "\r\n",
        "training_dataset_filename = 'emp_attr_train_parquet'\r\n",
        "testing_dataset_filename = 'emp_attr_test_parquet'\r\n",
        "\r\n",
        "\r\n",
        "training_data = Data(\r\n",
        "    name=training_dataset_filename,\r\n",
        "    path='data/train_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI employee attrition train data\",  \r\n",
        ")\r\n",
        "\r\n",
        "tr_data = ml_client.data.create_or_update(training_data)\r\n",
        "\r\n",
        "testing_data = Data(\r\n",
        "    name=testing_dataset_filename,\r\n",
        "    path='data/test_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI employee attrition test data\",  \r\n",
        ")\r\n",
        "\r\n",
        "te_data = ml_client.data.create_or_update(testing_data)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading train_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 57.5k/57.5k [00:00<00:00, 4.18MB/s]\n\u001b[39m\n\n\u001b[32mUploading test_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 39.3k/39.3k [00:00<00:00, 2.95MB/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.makedirs('component', exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile component/training.py\r\n",
        "\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import sys\r\n",
        "import os\r\n",
        "\r\n",
        "parent_dir =  os.path.dirname(os.getcwd())\r\n",
        " \r\n",
        "# setting path\r\n",
        "sys.path.append(parent_dir)\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.compose import make_column_selector as selector\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\r\n",
        "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()    \r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "\r\n",
        "    # Read in data\r\n",
        "    print(\"Reading data\")\r\n",
        "    all_training_data = pd.read_parquet(args.training_data)\r\n",
        "    target = all_training_data[args.target_column_name]\r\n",
        "    features = all_training_data.drop([args.target_column_name], axis = 1)  \r\n",
        "\r\n",
        "    # Transform string data to numeric\r\n",
        "    numerical_selector = selector(dtype_exclude=object, dtype_include=np.number)\r\n",
        "    categorical_selector = selector(dtype_include=object)\r\n",
        "\r\n",
        "    numerical_columns = numerical_selector(features)\r\n",
        "    categorical_columns = categorical_selector(features)\r\n",
        "\r\n",
        "    categorial_encoder = OneHotEncoder(handle_unknown=\"ignore\")\r\n",
        "    numerical_encoder = StandardScaler()\r\n",
        "\r\n",
        "    preprocessor = ColumnTransformer([\r\n",
        "    ('ordinal-encoder', categorial_encoder, categorical_columns),\r\n",
        "    ('standard_scaler', numerical_encoder, numerical_columns)])\r\n",
        "\r\n",
        "    clf = make_pipeline(preprocessor, LogisticRegression())\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\r\n",
        "\r\n",
        "    print(\"Training model...\") \r\n",
        "    \r\n",
        "    model = clf.fit(X_train, y_train)\r\n",
        "\r\n",
        " \r\n",
        "    # Saving model with mlflow - leave this section unchanged\r\n",
        "    model_dir =  \"./model_output\"\r\n",
        "    with tempfile.TemporaryDirectory() as td:\r\n",
        "        print(\"Saving model with MLFlow to temporary directory\")\r\n",
        "        tmp_output_dir = os.path.join(td, model_dir)\r\n",
        "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\r\n",
        "\r\n",
        "        print(\"Copying MLFlow model to output path\")\r\n",
        "        for file_name in os.listdir(tmp_output_dir):\r\n",
        "            print(\"  Copying: \", file_name)\r\n",
        "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\r\n",
        "            # an option, removing the need for listdir\r\n",
        "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting component/training.py\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "yaml_contents = f\"\"\"\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
        "name: rai_employee_attrition_training_component\n",
        "display_name: Employee Atrition classification training component for RAI example\n",
        "version: {rai_emp_attrition_classifier_version_string}\n",
        "type: command\n",
        "inputs:\n",
        "  training_data:\n",
        "    type: path\n",
        "  target_column_name:\n",
        "    type: string\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: path\n",
        "code: ./component/\n",
        "environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:{str(version)}\n",
        "\"\"\" + r\"\"\"\n",
        "command: >-\n",
        "  python training.py\n",
        "  --training_data ${{{{inputs.training_data}}}}\n",
        "  --target_column_name ${{{{inputs.target_column_name}}}}\n",
        "  --model_output ${{{{outputs.model_output}}}}\n",
        "\"\"\"\n",
        "\n",
        "yaml_filename = \"RAIEmployeeAttritionClassificationTrainingComponent.yaml\"\n",
        "\n",
        "with open(yaml_filename, 'w') as f:\n",
        "    f.write(yaml_contents.format(yaml_contents))\n",
        "    \n",
        "train_component_definition = load_component(\n",
        "    path=yaml_filename\n",
        ")\n",
        "\n",
        "ml_client.components.create_or_update(train_component_definition)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'rai_employee_attrition_training_component', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/testRG/providers/Microsoft.MachineLearningServices/workspaces/rai-ws/components/rai_employee_attrition_training_component/versions/48', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f938ab7e9a0>, 'serialize': <msrest.serialization.Serializer object at 0x7f938ab7e730>, 'command': 'python training.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/testRG/providers/Microsoft.MachineLearningServices/workspaces/rai-ws/codes/164610f2-914e-41af-9750-41a33828b2bc/versions/1', 'environment_variables': None, 'environment': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/testRG/providers/Microsoft.MachineLearningServices/workspaces/rai-ws/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/1', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'version': '48', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'Employee Atrition classification training component for RAI example', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'path'}, 'target_column_name': {'type': 'string'}}, 'outputs': {'model_output': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] Employee Atrition classification training component for RAI example at 0x7f938ab68b80>})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "\r\n",
        "model_name_suffix = int(time.time())\r\n",
        "model_base_name = 'rai_employee_attrition_model'"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "register_component =  ml_client.components.get(\r\n",
        "        name=\"register_model\", version=version\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "train_model_component = ml_client.components.get(\r\n",
        "    name=\"rai_employee_attrition_training_component\", version=rai_emp_attrition_classifier_version_string\r\n",
        ")\r\n",
        "emppayrate_train_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/train_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "emppayrate_test_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/test_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=compute_name,\r\n",
        "    description=\"Register Model for RAI Employee Attrition\",\r\n",
        "    experiment_name=f\"RAI_Employee_Attrition_Model_Training_{model_name_suffix}\",\r\n",
        ")\r\n",
        "def my_training_pipeline(target_column_name, training_data):\r\n",
        "    trained_model = train_component_definition(\r\n",
        "        target_column_name=target_column_name,\r\n",
        "        training_data=training_data\r\n",
        "    )\r\n",
        "    trained_model.set_limits(timeout=120)\r\n",
        "\r\n",
        "    _ = register_component(\r\n",
        "        model_input_path=trained_model.outputs.model_output,\r\n",
        "        model_base_name=model_base_name,\r\n",
        "        model_name_suffix=model_name_suffix,\r\n",
        "    )\r\n",
        "\r\n",
        "    return {}\r\n",
        "\r\n",
        "model_registration_pipeline_job = my_training_pipeline(target_column, emppayrate_train_parquet)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "import webbrowser\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "\r\n",
        "\r\n",
        "    # open the pipeline in web browser\r\n",
        "    webbrowser.open(created_job.services[\"Studio\"].endpoint)\r\n",
        "    \r\n",
        "    #assert created_job.status == 'Completed'\r\n",
        "    return created_job\r\n",
        "\r\n",
        "# This is the actual submission\r\n",
        "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Completed\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expected_model_id = f'{model_base_name}_{model_name_suffix}:1'"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categorical_numerical_data(all_data):\r\n",
        "    data_df = pd.read_parquet(all_data)\r\n",
        "    categorical = []\r\n",
        "    for col, value in data_df.iteritems():\r\n",
        "        if value.dtype == 'object':\r\n",
        "            categorical.append(col)\r\n",
        "    numerical = data_df.columns.difference(categorical)\r\n",
        "\r\n",
        "    categorical.remove('Attrition')\r\n",
        "    return categorical, numerical"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get categorical and numerical fields from training data\r\n",
        "categorical, numerical = get_categorical_numerical_data(source_data_path)\r\n",
        "print(\"categorical columns: \",  categorical)\r\n",
        "print(\"numerical field: \", numerical)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "categorical columns:  ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime']\nnumerical field:  Index(['Age', 'DailyRate', 'DistanceFromHome', 'Education',\n       'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel',\n       'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n       'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n       'YearsSinceLastPromotion', 'YearsWithCurrManager'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_model_component = ml_client.components.get(\r\n",
        "    name='fetch_registered_model', version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_constructor_component = ml_client.components.get(\r\n",
        "    name=\"rai_insights_constructor\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_counterfactual_component = ml_client.components.get(\r\n",
        "    name=\"rai_insights_counterfactual\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_causal_component = ml_client.components.get(\r\n",
        "    name=\"rai_insights_causal\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_explanation_component = ml_client.components.get(\r\n",
        "    name=\"rai_insights_explanation\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_erroranalysis_component = ml_client.components.get(\r\n",
        "    name=\"rai_insights_erroranalysis\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_gather_component = ml_client.components.get(\r\n",
        "    name=\"rai_insights_gather\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_scorecard_component = ml_client.components.get(\r\n",
        "    name=\"rai_score_card\", version=version\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "score_card_config_dict = {\r\n",
        "    \"Model\": {\r\n",
        "        \"ModelName\": \"Employee churn measure\",\r\n",
        "        \"ModelType\": \"Classification\",\r\n",
        "        \"ModelSummary\": \"This model provides a measure of employee leaving or staying with a company\"\r\n",
        "    },\r\n",
        "    \"Metrics\" :{\r\n",
        "        \"accuracy_score\": {\r\n",
        "            \"threshold\": \">=0.85\"\r\n",
        "        },\r\n",
        "    },\r\n",
        "    \"FeatureImportance\": { \r\n",
        "        \"top_n\": 10 \r\n",
        "    }, \r\n",
        "    \"DataExplorer\": { \r\n",
        "        \"features\": [ \r\n",
        "        \"YearsAtCompany\", \r\n",
        "        \"JobLevel\", \r\n",
        "        \"Age\"\r\n",
        "        ] \r\n",
        "    },\r\n",
        "    \"Fairness\": {\r\n",
        "        \"metric\": [\"accuracy_score\"],\r\n",
        "        \"sensitive_features\": [\"Gender\"],\r\n",
        "        \"fairness_evaluation_kind\": \"ratio\"\r\n",
        "    }\r\n",
        "\r\n",
        "}\r\n",
        "\r\n",
        "score_card_config_filename = \"rai_employee_attrition_score_card_config.json\"\r\n",
        "\r\n",
        "with open(score_card_config_filename, 'w') as f:\r\n",
        "    json.dump(score_card_config_dict, f)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "score_card_config_path = Input(\r\n",
        "    type=\"uri_file\",\r\n",
        "    path=score_card_config_filename,\r\n",
        "    mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "        compute=compute_name,\r\n",
        "        description=\"RAI computation on emp attrition classification data\",\r\n",
        "        experiment_name=f\"RAI_Employee_Attrition_Classification_RAIInsights_Computation_{model_name_suffix}\",\r\n",
        "    )\r\n",
        "def rai_classification_pipeline(\r\n",
        "        target_column_name,\r\n",
        "        training_data,\r\n",
        "        testing_data,\r\n",
        "        score_card_config_path,\r\n",
        "    ):\r\n",
        "\r\n",
        "        # Fetch the model\r\n",
        "        fetch_job = fetch_model_component(\r\n",
        "            model_id=expected_model_id\r\n",
        "        )\r\n",
        "        \r\n",
        "        # Initiate the RAIInsights\r\n",
        "        create_rai_job = rai_constructor_component(\r\n",
        "            title=\"RAI Dashboard\",\r\n",
        "            task_type=\"classification\",\r\n",
        "            model_info_path=fetch_job.outputs.model_info_output_path,\r\n",
        "            train_dataset=training_data,\r\n",
        "            test_dataset=testing_data,\r\n",
        "            target_column_name=target_column_name,\r\n",
        "            classes=json.dumps(['Staying', 'Leaving']),\r\n",
        "            categorical_column_names=json.dumps(categorical),\r\n",
        "        )\r\n",
        "        create_rai_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add an explanation\r\n",
        "        explain_job = rai_explanation_component(\r\n",
        "            comment=\"Explanation for employee attrition classification\",\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        explain_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add error analysis\r\n",
        "        erroranalysis_job = rai_erroranalysis_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        erroranalysis_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        # Add causal analysis\r\n",
        "        causal_job = rai_causal_component(\r\n",
        "            treatment_features=json.dumps(['Age', 'DailyRate', 'YearsAtCompany']),\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        causal_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add counterfactual analysis\r\n",
        "        counterfactual_job = rai_counterfactual_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            total_cfs=10,\r\n",
        "            desired_class='opposite',\r\n",
        "        )\r\n",
        "        counterfactual_job.set_limits(timeout=600)\r\n",
        "\r\n",
        "        # Combine everything\r\n",
        "        rai_gather_job = rai_gather_component(\r\n",
        "            constructor=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            insight_1=explain_job.outputs.explanation,\r\n",
        "            insight_2=causal_job.outputs.causal,\r\n",
        "            insight_3=counterfactual_job.outputs.counterfactual,\r\n",
        "            insight_4=erroranalysis_job.outputs.error_analysis,\r\n",
        "        )\r\n",
        "        rai_gather_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        rai_gather_job.outputs.dashboard.mode = \"upload\"\r\n",
        "        rai_gather_job.outputs.ux_json.mode = \"upload\"\r\n",
        "\r\n",
        "        # Generate score card in pdf format for a summary report on model performance,\r\n",
        "        # and observe distrbution of error between prediction vs ground truth.\r\n",
        "        rai_scorecard_job = rai_scorecard_component(\r\n",
        "            dashboard=rai_gather_job.outputs.dashboard,\r\n",
        "            pdf_generation_config=score_card_config_path\r\n",
        "        )\r\n",
        "\r\n",
        "        return {\r\n",
        "            \"dashboard\": rai_gather_job.outputs.dashboard,\r\n",
        "            \"ux_json\": rai_gather_job.outputs.ux_json,\r\n",
        "            \"scorecard\": rai_scorecard_job.outputs.scorecard\r\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "from azure.ai.ml import Output\r\n",
        "\r\n",
        "# Pipeline to construct the RAI Insights\r\n",
        "insights_pipeline_job = rai_classification_pipeline(\r\n",
        "    target_column_name=target_column,\r\n",
        "    training_data=emppayrate_train_parquet,\r\n",
        "    testing_data=emppayrate_test_parquet,\r\n",
        "    score_card_config_path=score_card_config_path,\r\n",
        ")\r\n",
        "\r\n",
        "# Workaround to enable the download\r\n",
        "rand_path = str(uuid.uuid4())\r\n",
        "insights_pipeline_job.outputs.dashboard = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "insights_pipeline_job.outputs.ux_json = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        "\r\n",
        ")\r\n",
        "insights_pipeline_job.outputs.scorecard = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/scorecard/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "\r\n",
        "# submit pipeline\r\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Completed\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_id = ml_client._operation_scope.subscription_id\r\n",
        "rg_name = ml_client._operation_scope.resource_group_name\r\n",
        "ws_name = ml_client.workspace_name\r\n",
        "\r\n",
        "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\r\n",
        "\r\n",
        "print(f\"Please visit {expected_uri} to see your analysis\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Please visit https://ml.azure.com/model/rai_employee_attrition_model_1662746159:1/model_analysis?wsid=/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourcegroups/testRG/workspaces/rai-ws to see your analysis\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_directory = \".\"\r\n",
        "\r\n",
        "ml_client.jobs.download(\r\n",
        "    insights_job.name, download_path=target_directory, output_name=\"scorecard\"\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Downloading artifact azureml://subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourcegroups/testRG/workspaces/rai-ws/datastores/workspaceblobstore/paths/de90cdba-8011-4a4d-9c94-358ac75085ad/scorecard/ to named-outputs/scorecard\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}