{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "conda install azure-common azure-ai-ml==0.1.0b7 mltable==0.1.0b4 azureml_dataprep azureml_dataprep_rslex responsibleai~=0.18.0 raiwidgets~=0.18.0 pandas pyarrow shap"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\nSolving environment: \\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\nSolving environment: - \b\bfailed with initial frozen solve. Retrying with flexible solve.\n\nPackagesNotFoundError: The following packages are not available from current channels:\n\n  - azureml_dataprep_rslex\n  - mltable==0.1.0b4\n  - azureml_dataprep\n  - azure-ai-ml==0.1.0b7\n  - raiwidgets~=0.18.0\n  - responsibleai~=0.18.0\n\nCurrent channels:\n\n  - https://repo.anaconda.com/pkgs/main/linux-64\n  - https://repo.anaconda.com/pkgs/main/noarch\n  - https://repo.anaconda.com/pkgs/r/linux-64\n  - https://repo.anaconda.com/pkgs/r/noarch\n\nTo search for alternate channels that may provide the conda package you're\nlooking for, navigate to\n\n    https://anaconda.org\n\nand use the search bar at the top of the page.\n\n\n\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335838547
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1667335838684
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "\n",
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1667335843555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azureml.mlflow import register_model\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "#connect to the workspace\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client =  MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:azure.ai.ml._utils._experimental:Class SystemCreatedStorageAccount: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nWARNING:azure.ai.ml._utils._experimental:Class SystemCreatedAcrAccount: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nFound the config file in: ./config.json\nClass RegistryOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1667335847275
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"trainingcompute\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335847413
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\r\n",
        "\r\n",
        "all_compute_names = [x.name for x in ml_client.compute.list()]\r\n",
        "\r\n",
        "if compute_name in all_compute_names:\r\n",
        "    print(f\"Found existing compute: {compute_name}\")\r\n",
        "else:\r\n",
        "    my_compute = AmlCompute(\r\n",
        "        name=compute_name,\r\n",
        "        size=\"Standard_DS2_v2\",\r\n",
        "        min_instances=0,\r\n",
        "        max_instances=4,\r\n",
        "        idle_time_before_scale_down=3600\r\n",
        "    )\r\n",
        "    ml_client.compute.begin_create_or_update(my_compute)\r\n",
        "    print(\"Initiated compute creation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute: trainingcompute\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335847730
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_emp_attrition_classifier_version_string = '2'\r\n",
        "version='1'"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335847871
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv('data/WA_Fn-UseC_-HR-Employee-Attrition.csv')"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335848038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(data_df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      Age Attrition     BusinessTravel  DailyRate              Department  \\\n0      41       Yes      Travel_Rarely       1102                   Sales   \n1      49        No  Travel_Frequently        279  Research & Development   \n2      37       Yes      Travel_Rarely       1373  Research & Development   \n3      33        No  Travel_Frequently       1392  Research & Development   \n4      27        No      Travel_Rarely        591  Research & Development   \n...   ...       ...                ...        ...                     ...   \n1465   36        No  Travel_Frequently        884  Research & Development   \n1466   39        No      Travel_Rarely        613  Research & Development   \n1467   27        No      Travel_Rarely        155  Research & Development   \n1468   49        No  Travel_Frequently       1023                   Sales   \n1469   34        No      Travel_Rarely        628  Research & Development   \n\n      DistanceFromHome  Education EducationField  EmployeeCount  \\\n0                    1          2  Life Sciences              1   \n1                    8          1  Life Sciences              1   \n2                    2          2          Other              1   \n3                    3          4  Life Sciences              1   \n4                    2          1        Medical              1   \n...                ...        ...            ...            ...   \n1465                23          2        Medical              1   \n1466                 6          1        Medical              1   \n1467                 4          3  Life Sciences              1   \n1468                 2          3        Medical              1   \n1469                 8          3        Medical              1   \n\n      EmployeeNumber  ...  RelationshipSatisfaction StandardHours  \\\n0                  1  ...                         1            80   \n1                  2  ...                         4            80   \n2                  4  ...                         2            80   \n3                  5  ...                         3            80   \n4                  7  ...                         4            80   \n...              ...  ...                       ...           ...   \n1465            2061  ...                         3            80   \n1466            2062  ...                         1            80   \n1467            2064  ...                         2            80   \n1468            2065  ...                         4            80   \n1469            2068  ...                         1            80   \n\n      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n0                    0                  8                      0   \n1                    1                 10                      3   \n2                    0                  7                      3   \n3                    0                  8                      3   \n4                    1                  6                      3   \n...                ...                ...                    ...   \n1465                 1                 17                      3   \n1466                 1                  9                      5   \n1467                 1                  6                      0   \n1468                 0                 17                      3   \n1469                 0                  6                      3   \n\n     WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n0                  1               6                  4   \n1                  3              10                  7   \n2                  3               0                  0   \n3                  3               8                  7   \n4                  3               2                  2   \n...              ...             ...                ...   \n1465               3               5                  2   \n1466               3               7                  7   \n1467               3               6                  2   \n1468               2               9                  6   \n1469               4               4                  3   \n\n      YearsSinceLastPromotion  YearsWithCurrManager  \n0                           0                     5  \n1                           1                     7  \n2                           0                     0  \n3                           3                     0  \n4                           2                     2  \n...                       ...                   ...  \n1465                        0                     3  \n1466                        1                     7  \n1467                        0                     3  \n1468                        0                     8  \n1469                        1                     2  \n\n[1470 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Attrition</th>\n      <th>BusinessTravel</th>\n      <th>DailyRate</th>\n      <th>Department</th>\n      <th>DistanceFromHome</th>\n      <th>Education</th>\n      <th>EducationField</th>\n      <th>EmployeeCount</th>\n      <th>EmployeeNumber</th>\n      <th>...</th>\n      <th>RelationshipSatisfaction</th>\n      <th>StandardHours</th>\n      <th>StockOptionLevel</th>\n      <th>TotalWorkingYears</th>\n      <th>TrainingTimesLastYear</th>\n      <th>WorkLifeBalance</th>\n      <th>YearsAtCompany</th>\n      <th>YearsInCurrentRole</th>\n      <th>YearsSinceLastPromotion</th>\n      <th>YearsWithCurrManager</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1102</td>\n      <td>Sales</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>279</td>\n      <td>Research &amp; Development</td>\n      <td>8</td>\n      <td>1</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1373</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>80</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>1392</td>\n      <td>Research &amp; Development</td>\n      <td>3</td>\n      <td>4</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>7</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>591</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>7</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1465</th>\n      <td>36</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>884</td>\n      <td>Research &amp; Development</td>\n      <td>23</td>\n      <td>2</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2061</td>\n      <td>...</td>\n      <td>3</td>\n      <td>80</td>\n      <td>1</td>\n      <td>17</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1466</th>\n      <td>39</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>613</td>\n      <td>Research &amp; Development</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2062</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1467</th>\n      <td>27</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>155</td>\n      <td>Research &amp; Development</td>\n      <td>4</td>\n      <td>3</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>2064</td>\n      <td>...</td>\n      <td>2</td>\n      <td>80</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1468</th>\n      <td>49</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>1023</td>\n      <td>Sales</td>\n      <td>2</td>\n      <td>3</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2065</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>0</td>\n      <td>17</td>\n      <td>3</td>\n      <td>2</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1469</th>\n      <td>34</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>628</td>\n      <td>Research &amp; Development</td>\n      <td>8</td>\n      <td>3</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2068</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>1470 rows × 35 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335848255
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Employee count as all values are 1 and hence attrition is independent of this feature\r\n",
        "data_df = data_df.drop(['EmployeeCount'], axis=1)\r\n",
        "# Dropping Employee Number since it is merely an identifier\r\n",
        "data_df = data_df.drop(['EmployeeNumber'], axis=1)\r\n",
        "data_df = data_df.drop(['Over18'], axis=1)\r\n",
        "\r\n",
        "# Since all values are 80\r\n",
        "data_df = data_df.drop(['StandardHours'], axis=1)\r\n",
        "\r\n",
        "# Changing target values to a more meaningful words\r\n",
        "target_map = {'Yes': 'Leaving', 'No': 'Staying'}\r\n",
        "data_df[\"Attrition\"] = data_df[\"Attrition\"].apply(lambda x: target_map[x])\r\n",
        "\r\n",
        "target_column = \"Attrition\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335848444
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data_df, test_size=0.3)\r\n",
        "\r\n",
        "train_data = train.to_parquet('data/train_dataset.parquet')\r\n",
        "test_data = test.to_parquet('data/test_dataset.parquet')"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335848631
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_data_path = 'data/all_emp_dataset.parquet'\r\n",
        "\r\n",
        "train_data = train.to_parquet('data/train_dataset.parquet')\r\n",
        "test_data = test.to_parquet('data/test_dataset.parquet')\r\n",
        "all_emp_data_parquet = data_df.to_parquet(source_data_path)\r\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335848836
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "\r\n",
        "training_dataset_filename = 'emp_attr_train_parquet'\r\n",
        "testing_dataset_filename = 'emp_attr_test_parquet'\r\n",
        "\r\n",
        "\r\n",
        "training_data = Data(\r\n",
        "    name=training_dataset_filename,\r\n",
        "    path='data/train_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI employee attrition train data\",  \r\n",
        ")\r\n",
        "\r\n",
        "tr_data = ml_client.data.create_or_update(training_data)\r\n",
        "\r\n",
        "testing_data = Data(\r\n",
        "    name=testing_dataset_filename,\r\n",
        "    path='data/test_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI employee attrition test data\",  \r\n",
        ")\r\n",
        "\r\n",
        "te_data = ml_client.data.create_or_update(testing_data)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading train_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 57.5k/57.5k [00:00<00:00, 1.87MB/s]\n\u001b[39m\n\n\u001b[32mUploading test_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 39.2k/39.2k [00:00<00:00, 2.66MB/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335851567
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.makedirs('component', exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335851750
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile component/training.py\r\n",
        "\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import sys\r\n",
        "import os\r\n",
        "\r\n",
        "parent_dir =  os.path.dirname(os.getcwd())\r\n",
        " \r\n",
        "# setting path\r\n",
        "sys.path.append(parent_dir)\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.compose import make_column_selector as selector\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\r\n",
        "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()    \r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "\r\n",
        "    # Read in data\r\n",
        "    print(\"Reading data\")\r\n",
        "    all_training_data = pd.read_parquet(args.training_data)\r\n",
        "    target = all_training_data[args.target_column_name]\r\n",
        "    features = all_training_data.drop([args.target_column_name], axis = 1)  \r\n",
        "\r\n",
        "    # Transform string data to numeric\r\n",
        "    numerical_selector = selector(dtype_exclude=object, dtype_include=np.number)\r\n",
        "    categorical_selector = selector(dtype_include=object)\r\n",
        "\r\n",
        "    numerical_columns = numerical_selector(features)\r\n",
        "    categorical_columns = categorical_selector(features)\r\n",
        "\r\n",
        "    categorial_encoder = OneHotEncoder(handle_unknown=\"ignore\")\r\n",
        "    numerical_encoder = StandardScaler()\r\n",
        "\r\n",
        "    preprocessor = ColumnTransformer([\r\n",
        "    ('ordinal-encoder', categorial_encoder, categorical_columns),\r\n",
        "    ('standard_scaler', numerical_encoder, numerical_columns)])\r\n",
        "\r\n",
        "    clf = make_pipeline(preprocessor, LogisticRegression())\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\r\n",
        "\r\n",
        "    print(\"Training model...\") \r\n",
        "    \r\n",
        "    model = clf.fit(X_train, y_train)\r\n",
        "\r\n",
        " \r\n",
        "    # Saving model with mlflow - leave this section unchanged\r\n",
        "    model_dir =  \"./model_output\"\r\n",
        "    with tempfile.TemporaryDirectory() as td:\r\n",
        "        print(\"Saving model with MLFlow to temporary directory\")\r\n",
        "        tmp_output_dir = os.path.join(td, model_dir)\r\n",
        "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\r\n",
        "\r\n",
        "        print(\"Copying MLFlow model to output path\")\r\n",
        "        for file_name in os.listdir(tmp_output_dir):\r\n",
        "            print(\"  Copying: \", file_name)\r\n",
        "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\r\n",
        "            # an option, removing the need for listdir\r\n",
        "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting component/training.py\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "yaml_contents = f\"\"\"\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
        "name: rai_employee_attrition_training_component\n",
        "display_name: Employee Atrition classification training component for RAI example\n",
        "version: {rai_emp_attrition_classifier_version_string}\n",
        "type: command\n",
        "inputs:\n",
        "  training_data:\n",
        "    type: path\n",
        "  target_column_name:\n",
        "    type: string\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: path\n",
        "code: ./component/\n",
        "environment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:{str(version)}\n",
        "\"\"\" + r\"\"\"\n",
        "command: >-\n",
        "  python training.py\n",
        "  --training_data ${{{{inputs.training_data}}}}\n",
        "  --target_column_name ${{{{inputs.target_column_name}}}}\n",
        "  --model_output ${{{{outputs.model_output}}}}\n",
        "\"\"\"\n",
        "\n",
        "yaml_filename = \"RAIEmployeeAttritionClassificationTrainingComponent.yaml\"\n",
        "\n",
        "with open(yaml_filename, 'w') as f:\n",
        "    f.write(yaml_contents.format(yaml_contents))\n",
        "    \n",
        "train_component_definition = load_component(\n",
        "    path=yaml_filename\n",
        ")\n",
        "\n",
        "ml_client.components.create_or_update(train_component_definition)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationException",
          "evalue": "One of (client, name, version), (source) should be provided.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(yaml_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(yaml_contents\u001b[38;5;241m.\u001b[39mformat(yaml_contents))\n\u001b[0;32m---> 32\u001b[0m train_component_definition \u001b[38;5;241m=\u001b[39m \u001b[43mload_component\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myaml_filename\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m ml_client\u001b[38;5;241m.\u001b[39mcomponents\u001b[38;5;241m.\u001b[39mcreate_or_update(train_component_definition)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/entities/_load_functions.py:380\u001b[0m, in \u001b[0;36mload_component\u001b[0;34m(source, relative_origin, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of (client, name, version), (source) should be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    381\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    382\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    383\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mCOMPONENT,\n\u001b[1;32m    384\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    385\u001b[0m         error_type\u001b[38;5;241m=\u001b[39mValidationErrorType\u001b[38;5;241m.\u001b[39mMISSING_FIELD,\n\u001b[1;32m    386\u001b[0m     )\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m component_entity\n",
            "\u001b[0;31mValidationException\u001b[0m: One of (client, name, version), (source) should be provided."
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1667335852554
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "\r\n",
        "model_name_suffix = int(time.time())\r\n",
        "model_base_name = 'rai_employee_attrition_model'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852871
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "register_component =  ml_client.components.get(\r\n",
        "        name=\"register_model\", version=version\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "train_model_component = ml_client.components.get(\r\n",
        "    name=\"rai_employee_attrition_training_component\", version=rai_emp_attrition_classifier_version_string\r\n",
        ")\r\n",
        "emppayrate_train_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/train_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "emppayrate_test_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/test_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=compute_name,\r\n",
        "    description=\"Register Model for RAI Employee Attrition\",\r\n",
        "    experiment_name=f\"RAI_Employee_Attrition_Model_Training_{model_name_suffix}\",\r\n",
        ")\r\n",
        "def my_training_pipeline(target_column_name, training_data):\r\n",
        "    trained_model = train_component_definition(\r\n",
        "        target_column_name=target_column_name,\r\n",
        "        training_data=training_data\r\n",
        "    )\r\n",
        "    trained_model.set_limits(timeout=120)\r\n",
        "\r\n",
        "    _ = register_component(\r\n",
        "        model_input_path=trained_model.outputs.model_output,\r\n",
        "        model_base_name=model_base_name,\r\n",
        "        model_name_suffix=model_name_suffix,\r\n",
        "    )\r\n",
        "\r\n",
        "    return {}\r\n",
        "\r\n",
        "model_registration_pipeline_job = my_training_pipeline(target_column, emppayrate_train_parquet)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "import webbrowser\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "\r\n",
        "\r\n",
        "    # open the pipeline in web browser\r\n",
        "    webbrowser.open(created_job.services[\"Studio\"].endpoint)\r\n",
        "    \r\n",
        "    #assert created_job.status == 'Completed'\r\n",
        "    return created_job\r\n",
        "\r\n",
        "# This is the actual submission\r\n",
        "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expected_model_id = f'{model_base_name}_{model_name_suffix}:1'\r\n",
        "azureml_model_id = f'azureml:{expected_model_id}'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852923
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categorical_numerical_data(all_data):\r\n",
        "    data_df = pd.read_parquet(all_data)\r\n",
        "    categorical = []\r\n",
        "    for col, value in data_df.iteritems():\r\n",
        "        if value.dtype == 'object':\r\n",
        "            categorical.append(col)\r\n",
        "    numerical = data_df.columns.difference(categorical)\r\n",
        "    categorical.remove('Attrition')\r\n",
        "    return categorical, numerical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852937
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get categorical and numerical fields from training data\r\n",
        "categorical, numerical = get_categorical_numerical_data(source_data_path)\r\n",
        "print(\"categorical columns: \",  categorical)\r\n",
        "print(\"numerical field: \", numerical)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852953
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"latest\"\r\n",
        "\r\n",
        "rai_constructor_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\r\n",
        ")\r\n",
        "\r\n",
        "rai_counterfactual_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_counterfactual\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_causal_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_causal\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_explanation_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_erroranalysis_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_gather_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852970
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "        compute=compute_name,\r\n",
        "        description=\"RAI computation on emp attrition classification data\",\r\n",
        "        experiment_name=f\"RAI_Employee_Attrition_Classification_RAIInsights_Computation_{model_name_suffix}\",\r\n",
        "    )\r\n",
        "def rai_classification_pipeline(\r\n",
        "        target_column_name,\r\n",
        "        training_data,\r\n",
        "        testing_data\r\n",
        "    ):\r\n",
        "        \r\n",
        "        # Initiate the RAIInsights\r\n",
        "        create_rai_job = rai_constructor_component(\r\n",
        "            title=\"RAI Dashboard\",\r\n",
        "            task_type=\"classification\",\r\n",
        "            model_info=expected_model_id,\r\n",
        "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),            \r\n",
        "            train_dataset=training_data,\r\n",
        "            test_dataset=testing_data,\r\n",
        "            target_column_name=target_column_name,\r\n",
        "            classes=json.dumps(['Staying', 'Leaving']),\r\n",
        "            categorical_column_names=json.dumps(categorical),\r\n",
        "        )\r\n",
        "        create_rai_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add an explanation\r\n",
        "        explain_job = rai_explanation_component(\r\n",
        "            comment=\"Explanation for employee attrition classification\",\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        explain_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add error analysis\r\n",
        "        erroranalysis_job = rai_erroranalysis_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        erroranalysis_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        # Add causal analysis\r\n",
        "        causal_job = rai_causal_component(\r\n",
        "            treatment_features=json.dumps(['JobRole', 'StockOptionLevel']),\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        causal_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add counterfactual analysis\r\n",
        "        counterfactual_job = rai_counterfactual_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            total_cfs=10,\r\n",
        "            desired_class='opposite',\r\n",
        "        )\r\n",
        "        counterfactual_job.set_limits(timeout=600)\r\n",
        "\r\n",
        "        # Combine everything\r\n",
        "        rai_gather_job = rai_gather_component(\r\n",
        "            constructor=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            insight_1=explain_job.outputs.explanation,\r\n",
        "            insight_2=causal_job.outputs.causal,\r\n",
        "            insight_3=counterfactual_job.outputs.counterfactual,\r\n",
        "            insight_4=erroranalysis_job.outputs.error_analysis,\r\n",
        "        )\r\n",
        "        rai_gather_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        rai_gather_job.outputs.dashboard.mode = \"upload\"\r\n",
        "        rai_gather_job.outputs.ux_json.mode = \"upload\"\r\n",
        "\r\n",
        "        return {\r\n",
        "            \"dashboard\": rai_gather_job.outputs.dashboard,\r\n",
        "            \"ux_json\": rai_gather_job.outputs.ux_json\r\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335852983
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "from azure.ai.ml import Output\r\n",
        "\r\n",
        "# Pipeline to construct the RAI Insights\r\n",
        "insights_pipeline_job = rai_classification_pipeline(\r\n",
        "    target_column_name=target_column,\r\n",
        "    training_data=emppayrate_train_parquet,\r\n",
        "    testing_data=emppayrate_test_parquet,\r\n",
        ")\r\n",
        "\r\n",
        "# Workaround to enable the download\r\n",
        "rand_path = str(uuid.uuid4())\r\n",
        "insights_pipeline_job.outputs.dashboard = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "insights_pipeline_job.outputs.ux_json = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        "\r\n",
        ")\r\n",
        "\r\n",
        "# submit pipeline\r\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335853001
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_id = ml_client._operation_scope.subscription_id\r\n",
        "rg_name = ml_client._operation_scope.resource_group_name\r\n",
        "ws_name = ml_client.workspace_name\r\n",
        "\r\n",
        "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\r\n",
        "\r\n",
        "print(f\"Please visit {expected_uri} to see your analysis\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335853014
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}