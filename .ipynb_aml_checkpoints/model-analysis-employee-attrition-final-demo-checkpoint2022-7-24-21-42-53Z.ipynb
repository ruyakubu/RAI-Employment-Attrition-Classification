{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade raiwidgets\n",
        "!pip install --upgrade pandas"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "\n",
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use IBM Employee Attrition Dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "def split_label(dataset, target_feature):\n",
        "    X = dataset.drop([target_feature], axis=1)\n",
        "    y = dataset[[target_feature]]\n",
        "    return X, y\n",
        "\n",
        "def clean_data(X, y, target_feature):\n",
        "    features = X.columns.values.tolist()\n",
        "    classes = y[target_feature].unique().tolist()\n",
        "    pipe_cfg = {\n",
        "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
        "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
        "    }\n",
        "    num_pipe = Pipeline([\n",
        "        ('num_imputer', SimpleImputer(strategy='median')),\n",
        "        ('num_scaler', StandardScaler())\n",
        "    ])\n",
        "    cat_pipe = Pipeline([\n",
        "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
        "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "    ])\n",
        "    feat_pipe = ColumnTransformer([\n",
        "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
        "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
        "    ])\n",
        "    X = feat_pipe.fit_transform(X)\n",
        "    print(pipe_cfg['cat_cols'])\n",
        "    return X, feat_pipe, features, classes\n",
        "\n",
        "\n",
        "\n",
        "outdirname = 'dataset.6.21.19'\n",
        "zipfilename = outdirname + '.zip'\n",
        "urlretrieve('https://publictestdatasets.blob.core.windows.net/data/' + zipfilename, zipfilename)\n",
        "with zipfile.ZipFile(zipfilename, 'r') as unzip:\n",
        "    unzip.extractall('.')\n",
        "all_data = pd.read_csv('./WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
        "\n",
        "# Dropping Employee count as all values are 1 and hence attrition is independent of this feature\n",
        "all_data = all_data.drop(['EmployeeCount'], axis=1)\n",
        "# Dropping Employee Number since it is merely an identifier\n",
        "all_data = all_data.drop(['EmployeeNumber'], axis=1)\n",
        "all_data = all_data.drop(['Over18'], axis=1)\n",
        "\n",
        "# Since all values are 80\n",
        "all_data = all_data.drop(['StandardHours'], axis=1)\n",
        "\n",
        "# Converting target variables from string to numerical values\n",
        "target_map = {'Yes': 'Leaving', 'No': 'Staying'}\n",
        "all_data[\"Attrition_numerical\"] = all_data[\"Attrition\"].apply(lambda x: target_map[x])\n",
        "all_data = all_data.drop(['Attrition'], axis=1)\n",
        "\n",
        "\n",
        "target_feature = \"Attrition_numerical\"\n",
        "\n",
        "\n",
        "\n",
        "X, y = split_label(all_data, target_feature)\n",
        "X_train_original, X_test_original, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=7)\n",
        "\n",
        "X_train, feat_pipe, features, classes = clean_data(X_train_original, y_train, target_feature)\n",
        "y_train = y_train[target_feature].to_numpy()\n",
        "\n",
        "X_test = feat_pipe.transform(X_test_original)\n",
        "y_test = y_test[target_feature].to_numpy()\n",
        "\n",
        "train_data = X_train_original.copy()\n",
        "train_data[target_feature] = y_train\n",
        "\n",
        "test_data = X_test_original.copy()\n",
        "test_data[target_feature] = y_test"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "clf = LGBMClassifier()\n",
        "model = clf.fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = []\n",
        "for col, value in all_data.iteritems():\n",
        "    if value.dtype == 'object':\n",
        "        categorical.append(col)\n",
        "numerical = all_data.columns.difference(categorical)\n",
        "#categorical.drop('Attrition_numerical')\n",
        "categorical.remove('Attrition_numerical')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "categorical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "numerical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Responsible AI model and dataset insights"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dashboard_pipeline = Pipeline(steps=[('preprocess', feat_pipe), ('model', model)])\n",
        "\n",
        "\n",
        "\n",
        "model_analysis2 = RAIInsights(dashboard_pipeline, train_data, test_data, target_feature, 'classification',\n",
        "                              categorical_features=categorical, \n",
        "                              classes=['Staying', 'Leaving'])\n",
        "\n",
        "# Queue Responsible AI insights\n",
        "model_analysis2.explainer.add()\n",
        "model_analysis2.counterfactual.add(10, desired_class='opposite')\n",
        "model_analysis2.error_analysis.add()\n",
        "model_analysis2.causal.add(treatment_features=['BusinessTravel', 'StockOptionLevel', 'WorkLifeBalance'])\n",
        "\n",
        "# Compute insights\n",
        "model_analysis2.compute()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ResponsibleAIDashboard(model_analysis2,\n",
        "                       feature_flights=\"newModelOverviewExperience\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}