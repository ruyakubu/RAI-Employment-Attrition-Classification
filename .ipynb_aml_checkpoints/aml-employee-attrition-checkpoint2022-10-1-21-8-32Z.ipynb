{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "conda install azure-common azure-ai-ml==0.1.0b7 mltable==0.1.0b4 azureml_dataprep azureml_dataprep_rslex responsibleai~=0.18.0 raiwidgets~=0.18.0 pandas pyarrow shap"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\nSolving environment: \\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\nSolving environment: - \b\bfailed with initial frozen solve. Retrying with flexible solve.\n\nPackagesNotFoundError: The following packages are not available from current channels:\n\n  - azure-ai-ml==0.1.0b7\n  - raiwidgets~=0.18.0\n  - azureml_dataprep\n  - azureml_dataprep_rslex\n  - responsibleai~=0.18.0\n  - mltable==0.1.0b4\n\nCurrent channels:\n\n  - https://repo.anaconda.com/pkgs/main/linux-64\n  - https://repo.anaconda.com/pkgs/main/noarch\n  - https://repo.anaconda.com/pkgs/r/linux-64\n  - https://repo.anaconda.com/pkgs/r/noarch\n\nTo search for alternate channels that may provide the conda package you're\nlooking for, navigate to\n\n    https://anaconda.org\n\nand use the search bar at the top of the page.\n\n\n\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335975355
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1667335975635
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pandas as pd\n",
        "\n",
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1667335980647
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azureml.mlflow import register_model\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "#connect to the workspace\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client =  MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:azure.ai.ml._utils._experimental:Class SystemCreatedStorageAccount: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nWARNING:azure.ai.ml._utils._experimental:Class SystemCreatedAcrAccount: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nFound the config file in: ./config.json\nClass RegistryOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1667335984625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"trainingcompute\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335984779
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\r\n",
        "\r\n",
        "all_compute_names = [x.name for x in ml_client.compute.list()]\r\n",
        "\r\n",
        "if compute_name in all_compute_names:\r\n",
        "    print(f\"Found existing compute: {compute_name}\")\r\n",
        "else:\r\n",
        "    my_compute = AmlCompute(\r\n",
        "        name=compute_name,\r\n",
        "        size=\"Standard_DS2_v2\",\r\n",
        "        min_instances=0,\r\n",
        "        max_instances=4,\r\n",
        "        idle_time_before_scale_down=3600\r\n",
        "    )\r\n",
        "    ml_client.compute.begin_create_or_update(my_compute)\r\n",
        "    print(\"Initiated compute creation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute: trainingcompute\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335984989
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_emp_attrition_classifier_version_string = '2'\r\n",
        "version='1'"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335985146
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv('data/WA_Fn-UseC_-HR-Employee-Attrition.csv')"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335985297
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(data_df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      Age Attrition     BusinessTravel  DailyRate              Department  \\\n0      41       Yes      Travel_Rarely       1102                   Sales   \n1      49        No  Travel_Frequently        279  Research & Development   \n2      37       Yes      Travel_Rarely       1373  Research & Development   \n3      33        No  Travel_Frequently       1392  Research & Development   \n4      27        No      Travel_Rarely        591  Research & Development   \n...   ...       ...                ...        ...                     ...   \n1465   36        No  Travel_Frequently        884  Research & Development   \n1466   39        No      Travel_Rarely        613  Research & Development   \n1467   27        No      Travel_Rarely        155  Research & Development   \n1468   49        No  Travel_Frequently       1023                   Sales   \n1469   34        No      Travel_Rarely        628  Research & Development   \n\n      DistanceFromHome  Education EducationField  EmployeeCount  \\\n0                    1          2  Life Sciences              1   \n1                    8          1  Life Sciences              1   \n2                    2          2          Other              1   \n3                    3          4  Life Sciences              1   \n4                    2          1        Medical              1   \n...                ...        ...            ...            ...   \n1465                23          2        Medical              1   \n1466                 6          1        Medical              1   \n1467                 4          3  Life Sciences              1   \n1468                 2          3        Medical              1   \n1469                 8          3        Medical              1   \n\n      EmployeeNumber  ...  RelationshipSatisfaction StandardHours  \\\n0                  1  ...                         1            80   \n1                  2  ...                         4            80   \n2                  4  ...                         2            80   \n3                  5  ...                         3            80   \n4                  7  ...                         4            80   \n...              ...  ...                       ...           ...   \n1465            2061  ...                         3            80   \n1466            2062  ...                         1            80   \n1467            2064  ...                         2            80   \n1468            2065  ...                         4            80   \n1469            2068  ...                         1            80   \n\n      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n0                    0                  8                      0   \n1                    1                 10                      3   \n2                    0                  7                      3   \n3                    0                  8                      3   \n4                    1                  6                      3   \n...                ...                ...                    ...   \n1465                 1                 17                      3   \n1466                 1                  9                      5   \n1467                 1                  6                      0   \n1468                 0                 17                      3   \n1469                 0                  6                      3   \n\n     WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n0                  1               6                  4   \n1                  3              10                  7   \n2                  3               0                  0   \n3                  3               8                  7   \n4                  3               2                  2   \n...              ...             ...                ...   \n1465               3               5                  2   \n1466               3               7                  7   \n1467               3               6                  2   \n1468               2               9                  6   \n1469               4               4                  3   \n\n      YearsSinceLastPromotion  YearsWithCurrManager  \n0                           0                     5  \n1                           1                     7  \n2                           0                     0  \n3                           3                     0  \n4                           2                     2  \n...                       ...                   ...  \n1465                        0                     3  \n1466                        1                     7  \n1467                        0                     3  \n1468                        0                     8  \n1469                        1                     2  \n\n[1470 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Attrition</th>\n      <th>BusinessTravel</th>\n      <th>DailyRate</th>\n      <th>Department</th>\n      <th>DistanceFromHome</th>\n      <th>Education</th>\n      <th>EducationField</th>\n      <th>EmployeeCount</th>\n      <th>EmployeeNumber</th>\n      <th>...</th>\n      <th>RelationshipSatisfaction</th>\n      <th>StandardHours</th>\n      <th>StockOptionLevel</th>\n      <th>TotalWorkingYears</th>\n      <th>TrainingTimesLastYear</th>\n      <th>WorkLifeBalance</th>\n      <th>YearsAtCompany</th>\n      <th>YearsInCurrentRole</th>\n      <th>YearsSinceLastPromotion</th>\n      <th>YearsWithCurrManager</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1102</td>\n      <td>Sales</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>279</td>\n      <td>Research &amp; Development</td>\n      <td>8</td>\n      <td>1</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1373</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>80</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>1392</td>\n      <td>Research &amp; Development</td>\n      <td>3</td>\n      <td>4</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>7</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>591</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>7</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1465</th>\n      <td>36</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>884</td>\n      <td>Research &amp; Development</td>\n      <td>23</td>\n      <td>2</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2061</td>\n      <td>...</td>\n      <td>3</td>\n      <td>80</td>\n      <td>1</td>\n      <td>17</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1466</th>\n      <td>39</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>613</td>\n      <td>Research &amp; Development</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2062</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5</td>\n      <td>3</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1467</th>\n      <td>27</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>155</td>\n      <td>Research &amp; Development</td>\n      <td>4</td>\n      <td>3</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>2064</td>\n      <td>...</td>\n      <td>2</td>\n      <td>80</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1468</th>\n      <td>49</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>1023</td>\n      <td>Sales</td>\n      <td>2</td>\n      <td>3</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2065</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>0</td>\n      <td>17</td>\n      <td>3</td>\n      <td>2</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1469</th>\n      <td>34</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>628</td>\n      <td>Research &amp; Development</td>\n      <td>8</td>\n      <td>3</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>2068</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>1470 rows × 35 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335985488
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Employee count as all values are 1 and hence attrition is independent of this feature\r\n",
        "data_df = data_df.drop(['EmployeeCount'], axis=1)\r\n",
        "# Dropping Employee Number since it is merely an identifier\r\n",
        "data_df = data_df.drop(['EmployeeNumber'], axis=1)\r\n",
        "data_df = data_df.drop(['Over18'], axis=1)\r\n",
        "\r\n",
        "# Since all values are 80\r\n",
        "data_df = data_df.drop(['StandardHours'], axis=1)\r\n",
        "\r\n",
        "# Changing target values to a more meaningful words\r\n",
        "target_map = {'Yes': 'Leaving', 'No': 'Staying'}\r\n",
        "data_df[\"Attrition\"] = data_df[\"Attrition\"].apply(lambda x: target_map[x])\r\n",
        "\r\n",
        "target_column = \"Attrition\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335985630
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data_df, test_size=0.3)\r\n",
        "\r\n",
        "train_data = train.to_parquet('data/train_dataset.parquet')\r\n",
        "test_data = test.to_parquet('data/test_dataset.parquet')"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335985809
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_data_path = 'data/all_emp_dataset.parquet'\r\n",
        "\r\n",
        "train_data = train.to_parquet('data/train_dataset.parquet')\r\n",
        "test_data = test.to_parquet('data/test_dataset.parquet')\r\n",
        "all_emp_data_parquet = data_df.to_parquet(source_data_path)\r\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335986178
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "\r\n",
        "training_dataset_filename = 'emp_attr_train_parquet'\r\n",
        "testing_dataset_filename = 'emp_attr_test_parquet'\r\n",
        "\r\n",
        "\r\n",
        "training_data = Data(\r\n",
        "    name=training_dataset_filename,\r\n",
        "    path='data/train_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI employee attrition train data\",  \r\n",
        ")\r\n",
        "\r\n",
        "tr_data = ml_client.data.create_or_update(training_data)\r\n",
        "\r\n",
        "testing_data = Data(\r\n",
        "    name=testing_dataset_filename,\r\n",
        "    path='data/test_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI employee attrition test data\",  \r\n",
        ")\r\n",
        "\r\n",
        "te_data = ml_client.data.create_or_update(testing_data)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading train_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 57.5k/57.5k [00:00<00:00, 3.43MB/s]\n\u001b[39m\n\n\u001b[32mUploading test_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 39.1k/39.1k [00:00<00:00, 2.11MB/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335988109
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.makedirs('component', exist_ok=True)\r\n",
        "os.makedirs('register_model_src', exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667335988278
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile component/training.py\r\n",
        "\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import sys\r\n",
        "import os\r\n",
        "\r\n",
        "parent_dir =  os.path.dirname(os.getcwd())\r\n",
        " \r\n",
        "# setting path\r\n",
        "sys.path.append(parent_dir)\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.compose import make_column_selector as selector\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\r\n",
        "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()    \r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "\r\n",
        "    # Read in data\r\n",
        "    print(\"Reading data\")\r\n",
        "    all_training_data = pd.read_parquet(args.training_data)\r\n",
        "    target = all_training_data[args.target_column_name]\r\n",
        "    features = all_training_data.drop([args.target_column_name], axis = 1)  \r\n",
        "\r\n",
        "    # Transform string data to numeric\r\n",
        "    numerical_selector = selector(dtype_exclude=object, dtype_include=np.number)\r\n",
        "    categorical_selector = selector(dtype_include=object)\r\n",
        "\r\n",
        "    numerical_columns = numerical_selector(features)\r\n",
        "    categorical_columns = categorical_selector(features)\r\n",
        "\r\n",
        "    categorial_encoder = OneHotEncoder(handle_unknown=\"ignore\")\r\n",
        "    numerical_encoder = StandardScaler()\r\n",
        "\r\n",
        "    preprocessor = ColumnTransformer([\r\n",
        "    ('ordinal-encoder', categorial_encoder, categorical_columns),\r\n",
        "    ('standard_scaler', numerical_encoder, numerical_columns)])\r\n",
        "\r\n",
        "    clf = make_pipeline(preprocessor, LogisticRegression())\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)\r\n",
        "\r\n",
        "    print(\"Training model...\") \r\n",
        "    \r\n",
        "    model = clf.fit(X_train, y_train)\r\n",
        "\r\n",
        " \r\n",
        "    # Saving model with mlflow - leave this section unchanged\r\n",
        "    model_dir =  \"./model_output\"\r\n",
        "    with tempfile.TemporaryDirectory() as td:\r\n",
        "        print(\"Saving model with MLFlow to temporary directory\")\r\n",
        "        tmp_output_dir = os.path.join(td, model_dir)\r\n",
        "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\r\n",
        "\r\n",
        "        print(\"Copying MLFlow model to output path\")\r\n",
        "        for file_name in os.listdir(tmp_output_dir):\r\n",
        "            print(\"  Copying: \", file_name)\r\n",
        "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\r\n",
        "            # an option, removing the need for listdir\r\n",
        "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting component/training.py\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "yaml_contents = f\"\"\"\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
        "name: rai_employee_attrition_training_component\n",
        "display_name: Employee Atrition classification training component for RAI example\n",
        "version: {rai_emp_attrition_classifier_version_string}\n",
        "type: command\n",
        "inputs:\n",
        "  training_data:\n",
        "    type: path\n",
        "  target_column_name:\n",
        "    type: string\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: path\n",
        "code: ./component/\n",
        "environment: azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4\n",
        "\"\"\" + r\"\"\"\n",
        "command: >-\n",
        "  python training.py\n",
        "  --training_data ${{{{inputs.training_data}}}}\n",
        "  --target_column_name ${{{{inputs.target_column_name}}}}\n",
        "  --model_output ${{{{outputs.model_output}}}}\n",
        "\"\"\"\n",
        "\n",
        "yaml_filename = \"RAIEmployeeAttritionClassificationTrainingComponent.yaml\"\n",
        "\n",
        "with open(yaml_filename, 'w') as f:\n",
        "    f.write(yaml_contents.format(yaml_contents))\n",
        "    \n",
        "train_component_definition = load_component(\n",
        "    source=yaml_filename\n",
        ")\n",
        "\n",
        "ml_client.components.create_or_update(train_component_definition)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading component (0.0 MBs): 100%|██████████| 3735/3735 [00:00<00:00, 89868.66it/s]\n\u001b[39m\n\nThis job/deployment uses curated environments. The syntax for using curated environments has changed to include azureml registry name: azureml:registries/azureml/environments//versions/ or azureml:registries/azureml/environments/labels/latest. Support for format you are using will be removed in future versions of the CLI and SDK. Learn more at aka.ms/curatedenv\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'rai_employee_attrition_training_component', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/components/rai_employee_attrition_training_component/versions/2', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f1829520160>, 'serialize': <msrest.serialization.Serializer object at 0x7f1829520760>, 'command': 'python training.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/codes/19993647-2a42-4002-a4de-8dd8fee65056/versions/1', 'environment_variables': None, 'environment': 'azureml://registries/azureml/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/1', 'distribution': None, 'resources': {'instance_count': 1}, 'version': '2', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'Employee Atrition classification training component for RAI example', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'path'}, 'target_column_name': {'type': 'string'}}, 'outputs': {'model_output': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1667336385965
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_contents = f\"\"\"\r\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\r\n",
        "name: register_model\r\n",
        "display_name: Register Model\r\n",
        "version: {rai_emp_attrition_classifier_version_string}\r\n",
        "type: command\r\n",
        "is_deterministic: False\r\n",
        "inputs:\r\n",
        "  model_input_path:\r\n",
        "    type: path\r\n",
        "  model_base_name:\r\n",
        "    type: string\r\n",
        "  model_name_suffix: # Set negative to use epoch_secs\r\n",
        "    type: integer\r\n",
        "    default: -1\r\n",
        "outputs:\r\n",
        "  model_info_output_path:\r\n",
        "    type: path\r\n",
        "code: ./register_model_src/\r\n",
        "environment: azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4\r\n",
        "command: >-\r\n",
        "  python register.py\r\n",
        "  --model_input_path ${{{{inputs.model_input_path}}}}\r\n",
        "  --model_base_name ${{{{inputs.model_base_name}}}}\r\n",
        "  --model_name_suffix ${{{{inputs.model_name_suffix}}}}\r\n",
        "  --model_info_output_path ${{{{outputs.model_info_output_path}}}}\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "yaml_filename = \"register.yaml\"\r\n",
        "\r\n",
        "with open(yaml_filename, 'w') as f:\r\n",
        "    f.write(yaml_contents)\r\n",
        "    \r\n",
        "register_component = load_component(\r\n",
        "    source=yaml_filename\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "\r\n",
        "model_name_suffix = int(time.time())\r\n",
        "model_base_name = 'rai_employee_attrition_model'"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386118
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "register_component =  ml_client.components.get(\r\n",
        "        name=\"register_model\", version=version\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "train_model_component = ml_client.components.get(\r\n",
        "    name=\"rai_employee_attrition_training_component\", version=rai_emp_attrition_classifier_version_string\r\n",
        ")\r\n",
        "emppayrate_train_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/train_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "emppayrate_test_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/test_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=compute_name,\r\n",
        "    description=\"Register Model for RAI Employee Attrition\",\r\n",
        "    experiment_name=f\"RAI_Employee_Attrition_Model_Training_{model_name_suffix}\",\r\n",
        ")\r\n",
        "def my_training_pipeline(target_column_name, training_data):\r\n",
        "    trained_model = train_component_definition(\r\n",
        "        target_column_name=target_column_name,\r\n",
        "        training_data=training_data\r\n",
        "    )\r\n",
        "    trained_model.set_limits(timeout=120)\r\n",
        "\r\n",
        "    _ = register_component(\r\n",
        "        model_input_path=trained_model.outputs.model_output,\r\n",
        "        model_base_name=model_base_name,\r\n",
        "        model_name_suffix=model_name_suffix,\r\n",
        "    )\r\n",
        "\r\n",
        "    return {}\r\n",
        "\r\n",
        "model_registration_pipeline_job = my_training_pipeline(target_column, emppayrate_train_parquet)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceNotFoundError",
          "evalue": "(UserError) Not found component register_model.\nCode: UserError\nMessage: Not found component register_model.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
            "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dsl, Input\n\u001b[0;32m----> 3\u001b[0m register_component \u001b[38;5;241m=\u001b[39m  \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregister_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m train_model_component \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39mcomponents\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m      9\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrai_employee_attrition_training_component\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39mrai_emp_attrition_classifier_version_string\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m emppayrate_train_parquet \u001b[38;5;241m=\u001b[39m Input(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/train_dataset.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownload\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/operations/_component_operations.py:193\u001b[0m, in \u001b[0;36mComponentOperations.get\u001b[0;34m(self, name, version, label)\u001b[0m\n\u001b[1;32m    177\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide either version or label.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    179\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    180\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mCOMPONENT,\n\u001b[1;32m    181\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    182\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m result \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version_operation\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    186\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    187\u001b[0m         version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[1;32m    188\u001b[0m         resource_group_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_group_name,\n\u001b[1;32m    189\u001b[0m         registry_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry_name,\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_args,\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry_name\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version_operation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    201\u001b[0m component \u001b[38;5;241m=\u001b[39m Component\u001b[38;5;241m.\u001b[39m_from_rest_object(result)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m component\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/_restclient/v2022_05_01/operations/_component_versions_operations.py:443\u001b[0m, in \u001b[0;36mComponentVersionsOperations.get\u001b[0;34m(self, resource_group_name, workspace_name, name, version, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m--> 443\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror, error_format\u001b[38;5;241m=\u001b[39mARMErrorFormat)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/core/exceptions.py:107\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    106\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
            "\u001b[0;31mResourceNotFoundError\u001b[0m: (UserError) Not found component register_model.\nCode: UserError\nMessage: Not found component register_model."
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "import webbrowser\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "\r\n",
        "\r\n",
        "    # open the pipeline in web browser\r\n",
        "    webbrowser.open(created_job.services[\"Studio\"].endpoint)\r\n",
        "    \r\n",
        "    #assert created_job.status == 'Completed'\r\n",
        "    return created_job\r\n",
        "\r\n",
        "# This is the actual submission\r\n",
        "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386802
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expected_model_id = f'{model_base_name}_{model_name_suffix}:1'\r\n",
        "azureml_model_id = f'azureml:{expected_model_id}'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386819
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categorical_numerical_data(all_data):\r\n",
        "    data_df = pd.read_parquet(all_data)\r\n",
        "    categorical = []\r\n",
        "    for col, value in data_df.iteritems():\r\n",
        "        if value.dtype == 'object':\r\n",
        "            categorical.append(col)\r\n",
        "    numerical = data_df.columns.difference(categorical)\r\n",
        "    categorical.remove('Attrition')\r\n",
        "    return categorical, numerical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386832
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get categorical and numerical fields from training data\r\n",
        "categorical, numerical = get_categorical_numerical_data(source_data_path)\r\n",
        "print(\"categorical columns: \",  categorical)\r\n",
        "print(\"numerical field: \", numerical)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"latest\"\r\n",
        "\r\n",
        "rai_constructor_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\r\n",
        ")\r\n",
        "\r\n",
        "rai_counterfactual_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_counterfactual\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_causal_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_causal\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_explanation_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_erroranalysis_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_gather_component = ml_client.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386861
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "        compute=compute_name,\r\n",
        "        description=\"RAI computation on emp attrition classification data\",\r\n",
        "        experiment_name=f\"RAI_Employee_Attrition_Classification_RAIInsights_Computation_{model_name_suffix}\",\r\n",
        "    )\r\n",
        "def rai_classification_pipeline(\r\n",
        "        target_column_name,\r\n",
        "        training_data,\r\n",
        "        testing_data\r\n",
        "    ):\r\n",
        "        \r\n",
        "        # Initiate the RAIInsights\r\n",
        "        create_rai_job = rai_constructor_component(\r\n",
        "            title=\"RAI Dashboard\",\r\n",
        "            task_type=\"classification\",\r\n",
        "            model_info=expected_model_id,\r\n",
        "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),            \r\n",
        "            train_dataset=training_data,\r\n",
        "            test_dataset=testing_data,\r\n",
        "            target_column_name=target_column_name,\r\n",
        "            classes=json.dumps(['Staying', 'Leaving']),\r\n",
        "            categorical_column_names=json.dumps(categorical),\r\n",
        "        )\r\n",
        "        create_rai_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add an explanation\r\n",
        "        explain_job = rai_explanation_component(\r\n",
        "            comment=\"Explanation for employee attrition classification\",\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        explain_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add error analysis\r\n",
        "        erroranalysis_job = rai_erroranalysis_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        erroranalysis_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        # Add causal analysis\r\n",
        "        causal_job = rai_causal_component(\r\n",
        "            treatment_features=json.dumps(['JobRole', 'StockOptionLevel']),\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        causal_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add counterfactual analysis\r\n",
        "        counterfactual_job = rai_counterfactual_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            total_cfs=10,\r\n",
        "            desired_class='opposite',\r\n",
        "        )\r\n",
        "        counterfactual_job.set_limits(timeout=600)\r\n",
        "\r\n",
        "        # Combine everything\r\n",
        "        rai_gather_job = rai_gather_component(\r\n",
        "            constructor=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            insight_1=explain_job.outputs.explanation,\r\n",
        "            insight_2=causal_job.outputs.causal,\r\n",
        "            insight_3=counterfactual_job.outputs.counterfactual,\r\n",
        "            insight_4=erroranalysis_job.outputs.error_analysis,\r\n",
        "        )\r\n",
        "        rai_gather_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        rai_gather_job.outputs.dashboard.mode = \"upload\"\r\n",
        "        rai_gather_job.outputs.ux_json.mode = \"upload\"\r\n",
        "\r\n",
        "        return {\r\n",
        "            \"dashboard\": rai_gather_job.outputs.dashboard,\r\n",
        "            \"ux_json\": rai_gather_job.outputs.ux_json\r\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386875
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "from azure.ai.ml import Output\r\n",
        "\r\n",
        "# Pipeline to construct the RAI Insights\r\n",
        "insights_pipeline_job = rai_classification_pipeline(\r\n",
        "    target_column_name=target_column,\r\n",
        "    training_data=emppayrate_train_parquet,\r\n",
        "    testing_data=emppayrate_test_parquet,\r\n",
        ")\r\n",
        "\r\n",
        "# Workaround to enable the download\r\n",
        "rand_path = str(uuid.uuid4())\r\n",
        "insights_pipeline_job.outputs.dashboard = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "insights_pipeline_job.outputs.ux_json = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        "\r\n",
        ")\r\n",
        "\r\n",
        "# submit pipeline\r\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_id = ml_client._operation_scope.subscription_id\r\n",
        "rg_name = ml_client._operation_scope.resource_group_name\r\n",
        "ws_name = ml_client.workspace_name\r\n",
        "\r\n",
        "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\r\n",
        "\r\n",
        "print(f\"Please visit {expected_uri} to see your analysis\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667336386909
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}